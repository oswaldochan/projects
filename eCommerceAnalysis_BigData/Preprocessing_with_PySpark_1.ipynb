{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing with PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L9FmJyt_s-P",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing with PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyCSw8jg60Fl",
        "colab_type": "text"
      },
      "source": [
        "## The 5 V's in this project. \n",
        "\n",
        "**Veracidad**: The dataset used was obtained from Kaggle. Its author is Michael Kechinov, CEO of REES46 eCommerce Marketing Platform.\n",
        "\n",
        "**Variability**: The data contained in the dataset is structured. There are datetime, strings, numerical and categorical data.\n",
        "\n",
        "**Volume:** The dataset has a weight of 5.3 gb. \n",
        "\n",
        "**Valence:** The variables of the data have a high level of connection. For example, the brand (*brand*) and the category (*category_code*).\n",
        "\n",
        "**Value:** The dataset has data that, worked correctly, generate great value to whoever uses it.\n",
        "(land) what added value it generates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuHBOG9sGXyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "63412fb6-5869-4bc4-ded8-d91fa953c367"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 64kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=407978a1ff6a0b950cb873acc1cf652d3b73f76f06d1b18d729bf631d8c496aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6VOUvsCyALP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b37fa4fe-fdb7-4a13-f185-d096eb267056"
      },
      "source": [
        "import pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# To apply user defined functions\n",
        "from pyspark.sql.functions import udf \n",
        "\n",
        "# To convert to date type\n",
        "from pyspark.sql.types import DateType\n",
        "\n",
        "# To select columns easier\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# To use datasets stored in my personal Drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')  # Choose file path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjX8At8KyfpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Spark Session called \"spark\", with app name \"eCommerce Analysis\"\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"eCommerce Analysis\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olsAnq5Ya7mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading data from personal Drive\n",
        "data = spark.read.csv(\"drive/My Drive/2019-Oct.csv\", header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiTZcWF1h3MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data.show(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkUpyPTSjleL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that removes \"UTC\" from the event_time data\n",
        "removerUTC = udf(lambda x:x[0:-4],StringType())\n",
        "\n",
        "# Apply function to \"event_time\" column\n",
        "# Store results in a new column called \"date_new\"\n",
        "data = data.withColumn('date_new', removerUTC('event_time'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haP8RXUkmevx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show distinct brands\n",
        "# data.where(\"brand\").distinct().show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xdK3quAmgqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the brands \n",
        "conteo_marcas = data.groupby(\"brand\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1G_pMZMpeWO",
        "colab_type": "text"
      },
      "source": [
        "# Date Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K1mZyW_mzae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that receives a date and returns the day\n",
        "convertToDay = udf(lambda x:x[8:10], StringType())\n",
        "\n",
        "# Apply the function to \"date_new\" column and save the result to a new column \"day_int\"\n",
        "data = data.withColumn('day_int', convertToDay('date_new'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8fb4TyIpk7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that receives a date and returns the hour\n",
        "convertToHour = udf(lambda x:x[11:13], StringType())\n",
        "\n",
        "# Apply the function to \"date_new\" column and save the result to a new column \"hour_int\"\n",
        "data = data.withColumn('hour_int', convertToHour('date_new'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwyP1sGlj-fn",
        "colab_type": "text"
      },
      "source": [
        "# Sold Products"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od0ajJFNjtvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See only purchased records\n",
        "ventas = data.where(data.event_type == \"purchase\")\n",
        "# ventas.show(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHve4BrqnA0h",
        "colab_type": "text"
      },
      "source": [
        "# Wordcloud data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fd3hMgOnEH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Most famous categories\n",
        "# Sort them in descending order\n",
        "conteo_categorias = data.groupby(\"category_code\").count().sort(col(\"count\").desc())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6fzkaZpnIXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See how many categories there are\n",
        "# conteo_categorias.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnimzrT0nJCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See the most popular category codes\n",
        "df_wordcloud = ventas.groupby(\"category_code\").count().sort(col(\"count\").desc())\n",
        "\n",
        "# Export data\n",
        "# Specify number of repartitions, so the results are saved in 1 single file\n",
        "# df_wordcloud.repartition(1).write.csv(\"wasb:///DatosExportados/WordNubeVENTAS.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atBHAfZN3MXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enable Arrow-based columnar data transfers\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"false\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QGwiNYz3XuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_wordcloud.toPandas().to_csv(\"WordNubeVentasFinal.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKo_BXA4Ib6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bec40add-f45a-4e55-9535-e908c9fb9ab4"
      },
      "source": [
        "!pip install pyarrow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (0.14.1)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvJIsFdwKHyB",
        "colab_type": "text"
      },
      "source": [
        "# Products that were added to a cart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPm8uiqvKDAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See only products added to the cart\n",
        "carritos = data.where(data.event_type == \"cart\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL9M9htQKMEl",
        "colab_type": "text"
      },
      "source": [
        "# Products that were viewed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3N6MNqeKDlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See only viewed products\n",
        "vista = data.where(data.event_type == \"view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48KuAahNnZIB",
        "colab_type": "text"
      },
      "source": [
        "# Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pldYRRT_na1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Group sold records by day and hour\n",
        "# Count the groups generated\n",
        "heatmap = ventas.groupBy([\"day_int\", \"hour_int\"]).agg({\"event_type\" : \"count\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFCTLAo6nfGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the data\n",
        "heatmap.toPandas().to_csv(\"HeatMap.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNllg36Jnf3-",
        "colab_type": "text"
      },
      "source": [
        "# Horizontal Bar Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCnpXGQinpaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Group each of the events (view, added to cart and sold) by day. And count the number of event types\n",
        "horizontal_bar1 = ventas.groupBy(\"day_int\").agg({\"event_type\" : \"count\"})\n",
        "horizontal_bar2 = carritos.groupBy(\"day_int\").agg({\"event_type\" : \"count\"})\n",
        "horizontal_bar3 = vista.groupBy(\"day_int\").agg({\"event_type\" : \"count\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLmgIaf5nuGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the data\n",
        "horizontal_bar1.toPandas().to_csv(\"HorizontalBarPlot1.csv\")\n",
        "horizontal_bar2.toPandas().to_csv(\"HorizontalBarPlot2.csv\")\n",
        "horizontal_bar3.toPandas().to_csv(\"HorizontalBarPlot3.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIu9hn8AKeZz",
        "colab_type": "text"
      },
      "source": [
        "# Histograms\n",
        "From horizontal_bar1, we saw the 5 main category codes, and then we generate a csv for each one of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIdk5QPokE8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate 5 different dataframes for each of the 5 main category codes\n",
        "hist_cat_1 = ventas.where(ventas.category_code == \"electronics.smartphone\")\n",
        "hist_cat_2 = ventas.where(ventas.category_code == \"electronics.audio.headphone\")\n",
        "hist_cat_3 = ventas.where(ventas.category_code == \"electronics.video.tv\")\n",
        "hist_cat_4 = ventas.where(ventas.category_code == \"electronics.clocks\")\n",
        "hist_cat_5 = ventas.where(ventas.category_code == \"appliances.kitchen.washer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCeVyE1en818",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export data\n",
        "hist_cat_1.toPandas().to_csv(\"Hist1.csv\")\n",
        "hist_cat_2.toPandas().to_csv(\"Hist2.csv\")\n",
        "hist_cat_3.toPandas().to_csv(\"Hist3.csv\")\n",
        "hist_cat_4.toPandas().to_csv(\"Hist4.csv\")\n",
        "hist_cat_5.toPandas().to_csv(\"Hist5.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP6hvskOKl79",
        "colab_type": "text"
      },
      "source": [
        "# Stacked Area Chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KKtfSkUpPCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Group each of the 5 main category codes by day\n",
        "# Count the number of records generated after grouping\n",
        "h1grouped = hist_cat_1.groupBy(\"day_int\").count()\n",
        "h2grouped = hist_cat_2.groupBy(\"day_int\").count()\n",
        "h3grouped = hist_cat_3.groupBy(\"day_int\").count()\n",
        "h4grouped = hist_cat_4.groupBy(\"day_int\").count()\n",
        "h5grouped = hist_cat_5.groupBy(\"day_int\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9SoYHRKrchA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export the data\n",
        "h1grouped.toPandas().to_csv(\"stacked1Nuevo.csv\")\n",
        "h2grouped.toPandas().to_csv(\"stacked2.csv\")\n",
        "h3grouped.toPandas().to_csv(\"stacked3.csv\")\n",
        "h4grouped.toPandas().to_csv(\"stacked4.csv\")\n",
        "h5grouped.toPandas().to_csv(\"stacked5.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}